{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e63b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:48.030750Z",
     "iopub.status.busy": "2023-04-28T01:16:48.030277Z",
     "iopub.status.idle": "2023-04-28T01:16:50.583213Z",
     "shell.execute_reply": "2023-04-28T01:16:50.582067Z"
    },
    "papermill": {
     "duration": 2.562908,
     "end_time": "2023-04-28T01:16:50.586003",
     "exception": false,
     "start_time": "2023-04-28T01:16:48.023095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid,save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy\n",
    "import itertools\n",
    "from PIL import Image\n",
    "# import cv2\n",
    "#watch -n 1 nvidia-smi --id=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbffd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:50.595670Z",
     "iopub.status.busy": "2023-04-28T01:16:50.594864Z",
     "iopub.status.idle": "2023-04-28T01:16:50.666908Z",
     "shell.execute_reply": "2023-04-28T01:16:50.665814Z"
    },
    "papermill": {
     "duration": 0.079283,
     "end_time": "2023-04-28T01:16:50.669358",
     "exception": false,
     "start_time": "2023-04-28T01:16:50.590075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.device_count()\n",
    "cuda = torch.cuda.is_available()\n",
    "print(f'cuda: {cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ccc7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:50.680025Z",
     "iopub.status.busy": "2023-04-28T01:16:50.678351Z",
     "iopub.status.idle": "2023-04-28T01:16:50.688013Z",
     "shell.execute_reply": "2023-04-28T01:16:50.687097Z"
    },
    "papermill": {
     "duration": 0.016635,
     "end_time": "2023-04-28T01:16:50.690074",
     "exception": false,
     "start_time": "2023-04-28T01:16:50.673439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "# Batch_size = 2\n",
    "# Learning_rate = 2e-4\n",
    "# # num_epochs = 100\n",
    "# # labda_cycle = 10\n",
    "# # lambda_identity = 1\n",
    "# load_model = False\n",
    "# save_model = True\n",
    "checkpoint_gen_PM = '/kaggle/input/weights/checkpoints/genpm.pth.tar'\n",
    "checkpoint_gen_MP = '/kaggle/input/weights/checkpoints/genmp.pth.tar'\n",
    "checkpoint_critic_P = '/kaggle/input/weights/checkpoints/criticp.pth.tar'\n",
    "checkpoint_critic_M = '/kaggle/input/weights/checkpoints/criticm.pth.tar'\n",
    "# root_photo = '/home/sanketwr/project1/practise /datasets/photo_jpg'\n",
    "# root_monet = '/home/sanketwr/project1/practise /datasets/monet_jpg'\n",
    "# transform = transforms.Compose([\n",
    "#     # transforms.ToTensor()\n",
    "#     # transforms.Resize(size=(256, 256)),\n",
    "#     transforms.RandomHorizontalFlip(p = 0.5),\n",
    "#     # transforms.RandomVerticalFlip(p =0.5),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdcde50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:50.698837Z",
     "iopub.status.busy": "2023-04-28T01:16:50.698554Z",
     "iopub.status.idle": "2023-04-28T01:16:50.708676Z",
     "shell.execute_reply": "2023-04-28T01:16:50.707814Z"
    },
    "papermill": {
     "duration": 0.016978,
     "end_time": "2023-04-28T01:16:50.710888",
     "exception": false,
     "start_time": "2023-04-28T01:16:50.693910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Discriminator\n",
    "# class Block(nn.Module):\n",
    "#     def __init__(self,in_channels,out_channels,stride):\n",
    "#         super().__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=in_channels,out_channels = out_channels,kernel_size=4,stride = stride,padding= 1,bias = True,padding_mode='reflect'),\n",
    "#             nn.InstanceNorm2d(out_channels),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#     def forward(self,x):\n",
    "#         return self.conv(x)\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self,in_channels=3,features = [64,128,256,512]):\n",
    "#         super().__init__()\n",
    "#         self.initial = nn.Sequential(\n",
    "#             nn.Conv2d(\n",
    "#             in_channels,\n",
    "#             features[0],\n",
    "#             kernel_size=4,\n",
    "#             stride=2,\n",
    "#             padding=1,\n",
    "#             padding_mode='reflect'\n",
    "#             ),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "\n",
    "#         layers = []\n",
    "#         in_channels = features[0]\n",
    "#         for feature in features[1:]:\n",
    "#             layers.append(Block(in_channels,feature,stride=1 if feature == features[-1] else 2))\n",
    "#             in_channels = feature\n",
    "\n",
    "#         layers.append(nn.Conv2d(in_channels,out_channels=3,kernel_size=4,stride=1,padding = 1,padding_mode='reflect'))\n",
    "#         self.model = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x = self.initial(x)\n",
    "#         return torch.sigmoid(self.model(x))\n",
    "    \n",
    "# def test():\n",
    "#     x = torch.randn((10,3,256,256))\n",
    "#     model = Discriminator()\n",
    "#     preds = model(x)\n",
    "#     # print(summary(model))\n",
    "#     print(preds.shape)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "    \n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # why normalize=False?\n",
    "            *self.block(in_channels, 64, normalize=False), # 3*256*256 -> 64*128*128 \n",
    "            *self.block(64, 128),  # 64*128*128 -> 128*64*64\n",
    "            *self.block(128, 256), # 128*64*64 -> 256*32*32\n",
    "            *self.block(256, 512), # 256*32*32 -> 512*16*16\n",
    "            \n",
    "            # Why padding first then convolution?\n",
    "            nn.ZeroPad2d((1,0,1,0)), # padding left and top   512*16*16 -> 512*17*17\n",
    "            nn.Conv2d(512, 1, 4, padding=1) # 512*17*17 -> 1*16*16\n",
    "        )\n",
    "        \n",
    "        self.scale_factor = 16\n",
    "    \n",
    "    @staticmethod\n",
    "    def block(in_channels, out_channels, normalize=True):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        return layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4679ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:50.719611Z",
     "iopub.status.busy": "2023-04-28T01:16:50.719344Z",
     "iopub.status.idle": "2023-04-28T01:16:51.168170Z",
     "shell.execute_reply": "2023-04-28T01:16:51.167032Z"
    },
    "papermill": {
     "duration": 0.455849,
     "end_time": "2023-04-28T01:16:51.170527",
     "exception": false,
     "start_time": "2023-04-28T01:16:50.714678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,down = True, use_act = True,**kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,padding_mode='reflect',**kwargs)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels,out_channels,**kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            # ConvBlock(channels,channels,kernel_size = 3, padding =1),\n",
    "            # # nn.InstanceNorm2d(channels),\n",
    "            # ConvBlock(channels,channels,use_act = False,kernel_size = 3,padding =1),\n",
    "            # # nn.InstanceNorm2d(channels),\n",
    "\n",
    "            nn.ReflectionPad2d(1), # padding, keep the image size constant after next conv2d\n",
    "            nn.Conv2d(channels, channels, kernel_size = 3),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,img_channels,num_features = 64,num_residuals = 9):\n",
    "        super().__init__()\n",
    "        self.inital = nn.Sequential(\n",
    "            nn.Conv2d(img_channels,num_features,kernel_size=7,stride = 1, padding=3,padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace = True),\n",
    "        )\n",
    "        self.down_blocks = nn.Sequential(\n",
    "                ConvBlock(num_features,num_features*2,kernel_size = 3,stride = 2,padding =1),\n",
    "                # nn.InstanceNorm2d(num_features*2),\n",
    "                ConvBlock(num_features*2,num_features*4,kernel_size = 3,stride = 2,padding =1),\n",
    "                # nn.InstanceNorm2d(num_features*4),\n",
    "                \n",
    "        )\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
    "        )\n",
    "        self.up_block = nn.Sequential(\n",
    "            \n",
    "                ConvBlock(num_features*4,num_features*2,down = False,kernel_size = 3,stride = 2,padding =1,output_padding = 1),\n",
    "                ConvBlock(num_features*2,num_features*1,down = False,kernel_size = 3,stride = 2,padding =1,output_padding = 1),                 \n",
    "            \n",
    "        )\n",
    "        self.last = nn.Conv2d(num_features*1,img_channels,kernel_size=7,stride = 1,padding=3,padding_mode='reflect')\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.inital(x)\n",
    "        # for layer in self.down_blocks:\n",
    "        x = self.down_blocks(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        # for layer in self.up_block(x):\n",
    "        x = self.up_block(x)\n",
    "        return torch.tanh(self.last(x))\n",
    "    \n",
    "def test():\n",
    "    img_channels =3\n",
    "    img_size = 256\n",
    "    x = torch.randn((2,img_channels,img_size,img_size))\n",
    "    gen = Generator(img_channels,9)\n",
    "    # print(summary(gen))\n",
    "    print(gen(x).shape) \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0088a9ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:51.180627Z",
     "iopub.status.busy": "2023-04-28T01:16:51.179669Z",
     "iopub.status.idle": "2023-04-28T01:16:51.189939Z",
     "shell.execute_reply": "2023-04-28T01:16:51.188918Z"
    },
    "papermill": {
     "duration": 0.017343,
     "end_time": "2023-04-28T01:16:51.192038",
     "exception": false,
     "start_time": "2023-04-28T01:16:51.174695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class customData(Dataset):\n",
    "    def __init__(self,root_A,root_B,mode='train',transform = None):\n",
    "        self.root_A = root_A #monet\n",
    "        self.root_B = root_B #photo\n",
    "        self.transform = transform\n",
    "        # self.image_A = os.listdir(self.root_A)[:4000]\n",
    "        # self.image_B = os.listdir(self.root_B)\n",
    "        if mode == 'train':\n",
    "            self.files_M = [os.path.join(root_A, name) for name in sorted(os.listdir(root_A))[:250]]\n",
    "            self.files_P = [os.path.join(root_B, name) for name in sorted(os.listdir(root_B))[:250]]\n",
    "        elif mode == 'test':\n",
    "            self.files_M = [os.path.join(root_A, name) for name in sorted(os.listdir(root_A))[250:]]\n",
    "            self.files_P = [os.path.join(root_B, name) for name in sorted(os.listdir(root_B))[250:301]]\n",
    "        \n",
    "\n",
    "        # self.length_dataset = max(len(self.image_A),len(self.image_B)) #7038,300\n",
    "        # self.len_A = len(self.image_A)\n",
    "        # self.len_B = len(self.image_B)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files_M)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        # image_path_A = os.path.join(self.root_A,self.image_A[idx % self.len_A])\n",
    "        # image_path_B = os.path.join(self.root_B,self.image_B[idx % self.len_B])\n",
    "        # image_A = read_image(image_path_A)\n",
    "        # image_B =  read_image(image_path_B)\n",
    "        file_M = self.files_M[idx]\n",
    "        file_P = self.files_P[idx]\n",
    "        img_M = Image.open(file_M)\n",
    "        img_P = Image.open(file_P)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_M = self.transform(img_M)\n",
    "            img_P = self.transform(img_P)\n",
    "        \n",
    "        return img_M, img_P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1837a43d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:51.201340Z",
     "iopub.status.busy": "2023-04-28T01:16:51.201065Z",
     "iopub.status.idle": "2023-04-28T01:16:51.211457Z",
     "shell.execute_reply": "2023-04-28T01:16:51.210348Z"
    },
    "papermill": {
     "duration": 0.018096,
     "end_time": "2023-04-28T01:16:51.214144",
     "exception": false,
     "start_time": "2023-04-28T01:16:51.196048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# criterion_GAN = nn.MSELoss().to(device)\n",
    "# criterion_cycle = nn.L1Loss().to(device)\n",
    "# criterion_identity = nn.L1Loss().to(device)\n",
    "# G_PM = Generator(img_channels = 3,num_residuals=9).to(device)\n",
    "# D_M  = Discriminator(in_channels=3).to(device=device)\n",
    "# G_MP = Generator(img_channels = 3,num_residuals=9).to(device)\n",
    "# D_P = Discriminator(in_channels=3).to(device=device)\n",
    "# c_Data_image = customData(root_monet,root_photo,transform=transform)\n",
    "lr =  0.0005\n",
    "b1 = 0.5\n",
    "b2 = 0.996\n",
    "\n",
    "# optimizer_G = optim.Adam(itertools.chain(G_PM.parameters(),G_MP.parameters()),lr = lr,betas=(b1,b2))\n",
    "# optimizer_D_M = optim.Adam(D_M.parameters(),lr = lr,betas=(b1,b2))\n",
    "# optimizer_D_P = optim.Adam(D_P.parameters(),lr = lr,betas=(b1,b2))\n",
    "\n",
    "## learning rate scheduler\n",
    "\n",
    "n_epochs = 120\n",
    "decay_epoch = 20\n",
    "\n",
    "\n",
    "# lambda_func = lambda epoch: 1 - max(0, epoch-decay_epoch)/(n_epochs-decay_epoch)\n",
    "\n",
    "# lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_func)\n",
    "# lr_scheduler_D_M = torch.optim.lr_scheduler.LambdaLR(optimizer_D_M, lr_lambda=lambda_func)\n",
    "# lr_scheduler_D_P = torch.optim.lr_scheduler.LambdaLR(optimizer_D_P, lr_lambda=lambda_func)\n",
    "\n",
    "# # c_Data_monet = customData(root_monet)\n",
    "# print(c_Data_image.__len__())\n",
    "# data_loader = DataLoader(c_Data_image,batch_size=Batch_size,shuffle=True)\n",
    "# # monet_loader = DataLoader(c_Data_monet,batch_size=batch_size,shuffle=True)\n",
    "# for i, [image_A,image_B] in enumerate(data_loader):\n",
    "#     if i == 1:\n",
    "#         break\n",
    "#     print(image_A.shape,image_B.shape)\n",
    "#     # images = TF.to_pil_image(images).convert('RGB')\n",
    "#     image_batch_np_A = make_grid(image_A,normalize=True).numpy()\n",
    "#     image_batch_np_B = make_grid(image_B,normalize=True).numpy()\n",
    "#     image_batch_np_A = np.transpose(image_batch_np_A,(1,2,0))\n",
    "#     image_batch_np_B = np.transpose(image_batch_np_B,(1,2,0))\n",
    "\n",
    "#     plt.figure(figsize=(1, 1))\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(\"Sample Images\")\n",
    "#     plt.imshow(image_batch_np_A)\n",
    "#     # plt.show()\n",
    "#     plt.figure(figsize=(1, 1))\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(\"Sample Images\")\n",
    "#     plt.imshow(image_batch_np_B)\n",
    "#     plt.show()\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "# trainloader = DataLoader(\n",
    "#     customData(root_monet,root_photo, mode='train', transform=transform),\n",
    "#     batch_size = batch_size,\n",
    "#     shuffle = True,\n",
    "    \n",
    "# )\n",
    "\n",
    "# testloader = DataLoader(\n",
    "#     customData(root_monet,root_photo, mode='test', transform=transform),\n",
    "#     batch_size = batch_size,\n",
    "#     shuffle = False,\n",
    "# )\n",
    "\n",
    "Tensor = (torch.cuda.FloatTensor) if device else torch.Tensor\n",
    "# Tensor = Tensor.to(device)\n",
    "def sample_images(real_M, real_P, figside=1.5):\n",
    "    assert real_M.size() == real_P.size(), 'The image size for two domains must be the same'\n",
    "    \n",
    "    G_PM.eval()\n",
    "    G_MP.eval()\n",
    "    \n",
    "    real_M = real_M.type(Tensor)#.to(device)\n",
    "    fake_P = G_MP(real_M).detach()\n",
    "    real_P = real_P.type(Tensor)#.to(device)\n",
    "    fake_M = G_PM(real_P).detach()\n",
    "    \n",
    "    nrows = real_M.size(0)\n",
    "    real_P = make_grid(real_P, nrow=nrows, normalize=True)\n",
    "    fake_M = make_grid(fake_M, nrow=nrows, normalize=True)\n",
    "    real_M = make_grid(real_M, nrow=nrows, normalize=True)\n",
    "    fake_P = make_grid(fake_P, nrow=nrows, normalize=True)\n",
    "    \n",
    "    image_grid = torch.cat((real_P, fake_M, real_M, fake_P), 1).cpu().permute(1, 2, 0)\n",
    "    \n",
    "    plt.figure(figsize=(figside*nrows, figside*4))\n",
    "    plt.imshow(image_grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6c8908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:51.222940Z",
     "iopub.status.busy": "2023-04-28T01:16:51.222591Z",
     "iopub.status.idle": "2023-04-28T01:16:51.227342Z",
     "shell.execute_reply": "2023-04-28T01:16:51.225731Z"
    },
    "papermill": {
     "duration": 0.011423,
     "end_time": "2023-04-28T01:16:51.229358",
     "exception": false,
     "start_time": "2023-04-28T01:16:51.217935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# real_M, real_P = next(iter(testloader))\n",
    "# sample_images(real_M, real_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5526ae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:51.238994Z",
     "iopub.status.busy": "2023-04-28T01:16:51.238171Z",
     "iopub.status.idle": "2023-04-28T01:16:51.244763Z",
     "shell.execute_reply": "2023-04-28T01:16:51.243831Z"
    },
    "papermill": {
     "duration": 0.013518,
     "end_time": "2023-04-28T01:16:51.246857",
     "exception": false,
     "start_time": "2023-04-28T01:16:51.233339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model,optimizer,filename = '/home/sanketwr/project1/practise /CV codes/checkpoints/cyclegan.pth.tar'):\n",
    "    # print('=> Saving Checkpoint')\n",
    "    checkpoint = {'model': model.state_dict(),\n",
    "              'optimizer': optimizer.state_dict(),\n",
    "              }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint_file,model,optimizer):\n",
    "    print('=> Loading checkpoint')\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "849a966f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:51.256146Z",
     "iopub.status.busy": "2023-04-28T01:16:51.255888Z",
     "iopub.status.idle": "2023-04-28T01:16:51.284375Z",
     "shell.execute_reply": "2023-04-28T01:16:51.283301Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.035928,
     "end_time": "2023-04-28T01:16:51.286521",
     "exception": false,
     "start_time": "2023-04-28T01:16:51.250593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_model = True\n",
    "def sample_images_(real_M, real_P, G_PM,G_MP,figside=1.5):\n",
    "    assert real_M.size() == real_P.size(), 'The image size for two domains must be the same'\n",
    "    \n",
    "    G_PM.eval()\n",
    "    G_MP.eval()\n",
    "    \n",
    "    real_M = real_M.type(Tensor)#.to(device)\n",
    "    fake_P = G_MP(real_M).detach()\n",
    "    real_P = real_P.type(Tensor)#.to(device)\n",
    "    fake_M = G_PM(real_P).detach()\n",
    "    \n",
    "    nrows = real_M.size(0)\n",
    "    real_P = make_grid(real_P, nrow=nrows, normalize=True)\n",
    "    fake_M = make_grid(fake_M, nrow=nrows, normalize=True)\n",
    "    real_M = make_grid(real_M, nrow=nrows, normalize=True)\n",
    "    fake_P = make_grid(fake_P, nrow=nrows, normalize=True)\n",
    "    \n",
    "    image_grid = torch.cat((real_P, fake_M, real_M, fake_P), 1).cpu().permute(1, 2, 0)\n",
    "    \n",
    "    plt.figure(figsize=(figside*nrows, figside*4))\n",
    "    plt.imshow(image_grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def train_fn(D_M,D_P,G_MP,G_PM,trainloader,testloader,optimizer_D_M,optimizer_D_P,optimizer_G,criterion_GAN,criterion_cycle,criterion_identity,d_scaler,g_scaler,epoch,lr_scheduler_G,lr_scheduler_D_M,lr_scheduler_D_P):\n",
    "    loop = tqdm(trainloader,leave = True)\n",
    "    for idx , (real_M,real_P) in enumerate(loop):\n",
    "\n",
    "        real_M, real_P = real_M.type(Tensor).to(device), real_P.type(Tensor).to(device)\n",
    "        \n",
    "        # groud truth\n",
    "        out_shape = [real_M.size(0), 1, real_M.size(2)//16, real_P.size(3)//16]\n",
    "        valid = torch.ones(out_shape).type(Tensor).to(device)\n",
    "        fake = torch.zeros(out_shape).type(Tensor).to(device)\n",
    "        \"\"\"Train Generators\"\"\"\n",
    "        # set to training mode in the begining, beacause sample_images will set it to eval mode\n",
    "        G_MP.train()\n",
    "        G_PM.train()\n",
    "        fake_P = G_MP(real_M)\n",
    "        fake_M = G_PM(real_P)\n",
    "        # trainig generators :\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        # identity loss\n",
    "        loss_id_M = criterion_identity(fake_P, real_M)\n",
    "        loss_id_P = criterion_identity(fake_M, real_P)\n",
    "        loss_identity = (loss_id_M + loss_id_P) / 2\n",
    "        \n",
    "        # GAN loss, train G to make D think it's true\n",
    "        loss_GAN_MP = criterion_GAN(D_P(fake_P), valid) \n",
    "        loss_GAN_PM = criterion_GAN(D_M(fake_M), valid)\n",
    "        loss_GAN = (loss_GAN_MP + loss_GAN_PM) / 2\n",
    "        \n",
    "        # cycle loss\n",
    "        recov_M = G_PM(fake_P)\n",
    "        recov_P = G_MP(fake_M)\n",
    "        loss_cycle_M = criterion_cycle(recov_M, real_M)\n",
    "        loss_cycle_P = criterion_cycle(recov_P, real_P)\n",
    "        loss_cycle = (loss_cycle_M + loss_cycle_P) / 2\n",
    "        \n",
    "        # G totol loss\n",
    "        loss_G = 5.0*loss_identity + loss_GAN + 10.0*loss_cycle\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "            \n",
    "        # with torch.cuda.amp.autocast():\n",
    "        loss_real = criterion_GAN(D_M(real_M), valid)\n",
    "        loss_fake = criterion_GAN(D_M(fake_M.detach()), fake)\n",
    "        loss_D_M = (loss_real + loss_fake) / 2\n",
    "            \n",
    "            \n",
    "        \"\"\"Train Discriminator B\"\"\"\n",
    "            \n",
    "            \n",
    "        loss_real = criterion_GAN(D_P(real_P), valid)\n",
    "        loss_fake = criterion_GAN(D_P(fake_P.detach()), fake)\n",
    "        loss_D_P = (loss_real + loss_fake) / 2\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        optimizer_D_M.zero_grad()\n",
    "        loss_D_M.backward()\n",
    "        optimizer_D_M.step()\n",
    "\n",
    "        optimizer_D_P.zero_grad()\n",
    "        # d_scaler.scale(loss_D_P).backward()\n",
    "        # d_scaler.step(optimizer_D_P)\n",
    "        # d_scaler.update()\n",
    "        loss_D_P.backward()\n",
    "        optimizer_D_P.step()\n",
    "        \n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        test_real_M, test_real_P = next(iter(testloader))\n",
    "        sample_images_(test_real_M, test_real_P,G_PM,G_MP)\n",
    "\n",
    "\n",
    "    loss_D = (loss_D_M + loss_D_P) / 2\n",
    "    print(f'[Epoch {epoch+1}/{n_epochs}]')\n",
    "    print(f'[G loss: {loss_G.item()} | identity: {loss_identity.item()} GAN: {loss_GAN.item()} cycle: {loss_cycle.item()}]')\n",
    "    print(f'[D loss: {loss_D.item()} | D_A: {loss_D_M.item()} D_B: {loss_D_P.item()}]')    \n",
    "\n",
    "            \n",
    "def main(l):\n",
    "    # load_model = True\n",
    "    # disc_P = Discriminator(in_channels=3).to(device=device)\n",
    "    # disc_M = Disc/riminator(in_channels=3).to(device=device)\n",
    "\n",
    "    # gen_PM = Generator(img_channels = 3,num_residuals=9).to(device) \n",
    "    # gen_MP = Generator(img_channels = 3,num_residuals=9).to(device)\n",
    "\n",
    "    \n",
    "    G_PM = Generator(img_channels = 3,num_residuals=9).to(device)\n",
    "    D_M  = Discriminator(in_channels=3).to(device=device)\n",
    "    G_MP = Generator(img_channels = 3,num_residuals=9).to(device)\n",
    "    D_P = Discriminator(in_channels=3).to(device=device)\n",
    "    \n",
    "    optimizer_G = optim.Adam(itertools.chain(G_MP.parameters(),G_PM.parameters()),lr = lr,betas=(b1,b2))\n",
    "    optimizer_D_M = optim.Adam(D_M.parameters(),lr = lr,betas=(b1,b2))\n",
    "    optimizer_D_P = optim.Adam(D_P.parameters(),lr = lr,betas=(b1,b2))\n",
    "        \n",
    "    lambda_func = lambda epoch: 1 - max(0, epoch-decay_epoch)/(n_epochs-decay_epoch)\n",
    "    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_func)\n",
    "    lr_scheduler_D_M = torch.optim.lr_scheduler.LambdaLR(optimizer_D_M, lr_lambda=lambda_func)\n",
    "    lr_scheduler_D_P = torch.optim.lr_scheduler.LambdaLR(optimizer_D_P, lr_lambda=lambda_func)\n",
    "\n",
    "\n",
    "    criterion_GAN = nn.MSELoss().to(device)\n",
    "    criterion_cycle = nn.L1Loss().to(device)\n",
    "    criterion_identity = nn.L1Loss().to(device)\n",
    "\n",
    "    if load_model:\n",
    "        load_checkpoint(\n",
    "            checkpoint_critic_M,D_M,optimizer_D_M,Learning_rate,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            checkpoint_critic_P,D_P,optimizer_D_P,Learning_rate,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            checkpoint_gen_MP,G_MP,optimizer_G,Learning_rate,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            checkpoint_gen_PM,G_PM,optimizer_G,Learning_rate,\n",
    "        )\n",
    "    batch_size = 2\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "        customData(root_monet,root_photo, mode='train', transform=transform),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        \n",
    "    )\n",
    "\n",
    "    testloader = DataLoader(\n",
    "        customData(root_monet,root_photo, mode='test', transform=transform),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False,\n",
    "    )\n",
    "\n",
    "    g_scaler = torch.cuda.amp.GradScaler()\n",
    "    d_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_fn(D_M,D_P,G_MP,G_PM,trainloader,testloader,optimizer_D_M,optimizer_D_P,optimizer_G,criterion_GAN,criterion_cycle,criterion_identity,d_scaler,g_scaler,epoch,lr_scheduler_G,lr_scheduler_D_M,lr_scheduler_D_P)\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_M.step()\n",
    "        lr_scheduler_D_P.step()\n",
    "        if save_model:\n",
    "            print('saving checkpoints')\n",
    "            save_checkpoint(G_MP,optimizer_G,filename=checkpoint_gen_MP)\n",
    "            save_checkpoint(G_PM,optimizer_G,filename=checkpoint_gen_PM)\n",
    "            save_checkpoint(D_M,optimizer_D_M,filename=checkpoint_critic_M)\n",
    "            save_checkpoint(D_P,optimizer_D_P,filename=checkpoint_critic_P)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    l = 0\n",
    "#     main(l)           \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "129a80b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:51.295963Z",
     "iopub.status.busy": "2023-04-28T01:16:51.295686Z",
     "iopub.status.idle": "2023-04-28T01:19:49.797662Z",
     "shell.execute_reply": "2023-04-28T01:19:49.796627Z"
    },
    "papermill": {
     "duration": 178.51026,
     "end_time": "2023-04-28T01:19:49.800546",
     "exception": false,
     "start_time": "2023-04-28T01:16:51.290286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "# root_photo = \"/kaggle/input/gan-getting-started\"\n",
    "root_photo =\"/kaggle/input/gan-getting-started/photo_jpg\"# os.path.join(root_photo, 'photo_jpg')\n",
    "files = [os.path.join(root_photo, name) for name in os.listdir(root_photo)]\n",
    "len(files)\n",
    "save_dir = '../images'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "generate_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "to_image = transforms.ToPILImage()\n",
    "G_PM = Generator(img_channels = 3,num_residuals=9).to(device)\n",
    "D_M  = Discriminator(in_channels=3).to(device=device)\n",
    "G_MP = Generator(img_channels = 3,num_residuals=9).to(device)\n",
    "D_P = Discriminator(in_channels=3).to(device=device)\n",
    "optimizer_G = optim.Adam(itertools.chain(G_MP.parameters(),G_PM.parameters()),lr = lr,betas=(b1,b2))\n",
    "optimizer_D_M = optim.Adam(D_M.parameters(),lr = lr,betas=(b1,b2))\n",
    "optimizer_D_P = optim.Adam(D_P.parameters(),lr = lr,betas=(b1,b2))\n",
    "\n",
    "load_checkpoint(\n",
    "            checkpoint_critic_M,D_M,optimizer_D_M,\n",
    ")\n",
    "load_checkpoint(\n",
    "    checkpoint_critic_P,D_P,optimizer_D_P,\n",
    ")\n",
    "load_checkpoint(\n",
    "    checkpoint_gen_MP,G_MP,optimizer_G,\n",
    ")\n",
    "load_checkpoint(\n",
    "    checkpoint_gen_PM,G_PM,optimizer_G,\n",
    ")\n",
    "\n",
    "G_PM.eval()\n",
    "batch_size = 5\n",
    "for i in range(0, len(files), batch_size):\n",
    "    # read images\n",
    "    imgs = []\n",
    "    for j in range(i, min(len(files), i+batch_size)):\n",
    "        img = Image.open(files[j])\n",
    "        img = generate_transforms(img)\n",
    "        imgs.append(img)\n",
    "    imgs = torch.stack(imgs, 0).type(Tensor)\n",
    "    \n",
    "    # generate\n",
    "    fake_imgs = G_PM(imgs).detach().cpu()\n",
    "    \n",
    "    # save\n",
    "    for j in range(fake_imgs.size(0)):\n",
    "        img = fake_imgs[j].squeeze().permute(1, 2, 0)\n",
    "        img_arr = img.numpy()\n",
    "        img_arr = (img_arr - np.min(img_arr)) * 255 / (np.max(img_arr) - np.min(img_arr))\n",
    "        img_arr = img_arr.astype(np.uint8)\n",
    "        \n",
    "        img = to_image(img_arr)\n",
    "        _, name = os.path.split(files[i+j])\n",
    "        img.save(os.path.join(save_dir, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16aa07cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:19:49.812625Z",
     "iopub.status.busy": "2023-04-28T01:19:49.811688Z",
     "iopub.status.idle": "2023-04-28T01:19:54.192097Z",
     "shell.execute_reply": "2023-04-28T01:19:54.191101Z"
    },
    "papermill": {
     "duration": 4.387991,
     "end_time": "2023-04-28T01:19:54.194462",
     "exception": false,
     "start_time": "2023-04-28T01:19:49.806471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/images.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11566000",
   "metadata": {
    "papermill": {
     "duration": 0.004024,
     "end_time": "2023-04-28T01:19:54.203049",
     "exception": false,
     "start_time": "2023-04-28T01:19:54.199025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d922c",
   "metadata": {
    "papermill": {
     "duration": 0.003906,
     "end_time": "2023-04-28T01:19:54.211335",
     "exception": false,
     "start_time": "2023-04-28T01:19:54.207429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eba44c",
   "metadata": {
    "papermill": {
     "duration": 0.003935,
     "end_time": "2023-04-28T01:19:54.219521",
     "exception": false,
     "start_time": "2023-04-28T01:19:54.215586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 197.886757,
   "end_time": "2023-04-28T01:19:56.640845",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-28T01:16:38.754088",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
